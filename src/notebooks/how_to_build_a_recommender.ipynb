{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build a Recommender in Python\n",
    "\n",
    "\n",
    "### by Maria Dominguez (aka Chi) & João Ascensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "\n",
    "#### Leveraging Python's data stack to build a music recommender, not unlike Spotify's Discover Weekly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "* Implicit and explicit feedback\n",
    "* Uniplaces and Data Science Academy logos at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems:\n",
    "\n",
    "Recommender systems present *items* that are likely to interest the *user*, by comparing the user's profile (inferred from *data*) to reference characteristics.\n",
    "\n",
    "Thus, our general framework contains three main components:\n",
    "\n",
    "* **Users**: the people in our system, that generate data and will receive item recommendations\n",
    "* **Items**: the things in our system, with which the users interact and that we want to recommend to them\n",
    "* **Data**: the different ways an user can express opinions about our items, i.e. where users and items meet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Recommendations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Word out there](https://hackernoon.com/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe), is that Spotify's Discover Weekly mixes together two well-known types of recommenders:\n",
    "\n",
    "* **Content-based filtering**: combines data (e.g. clicks, playcounts, ) and item attributes (e.g. content, text, tags, metadata) to create *user profiles*\n",
    "\n",
    "    * **Natural language processing (NLP)**: representing artists and tracks with features extracted from text (e.g. description, comments, tags)\n",
    "    * **Audio models**: extracting features by analyzing the raw audio tracks.\n",
    "    \n",
    "    \n",
    "* **Collaborative filtering**: analyzes user historical behaviour to find similarities across pairs of users and/or items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recommender:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data from the lastfm dataset, our prototype will include:\n",
    "\n",
    "* A content-based filtering branch, based on processing the tags assigned by the users to each artist (no raw audio analysis today, bummer)\n",
    "* A collaborative-filtering approach, using user/artist playcounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based filtering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import a file we prepared containing a bunch of tags relative to the artists in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the train dataset\n",
    "\n",
    "We want to read the dataset into a `train` dataframe, containing `user_id`, `artist_id`, `artist_name` and `play_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>play_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
       "      <td>melissa etheridge</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8</td>\n",
       "      <td>juliette &amp; the licks</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>21f3573f-10cf-44b3-aeaa-26cccd8448b5</td>\n",
       "      <td>the black dahlia murder</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "\n",
       "                              artist_id              artist_name  play_counts  \n",
       "0  b3ae82c2-e60b-4551-a76d-6620f1b456aa        melissa etheridge          897  \n",
       "1  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8     juliette & the licks          706  \n",
       "2  21f3573f-10cf-44b3-aeaa-26cccd8448b5  the black dahlia murder          507  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "train_cols = ['user_id', 'artist_id', 'artist_name', 'play_counts']\n",
    "train = pd.read_csv(\"../data/data/train.csv\", header=None, names=train_cols)\n",
    "# We checked, there are no missing values :)\n",
    "train.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we don't need the artist name for now. We will store in a separate dataframe to use in the last step, to provide nicer looking recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>play_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>b3ae82c2-e60b-4551-a76d-6620f1b456aa</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00000c289a1829a808ac09c00daf10bc3c4e223b</td>\n",
       "      <td>21f3573f-10cf-44b3-aeaa-26cccd8448b5</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  \\\n",
       "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
       "\n",
       "                              artist_id  play_counts  \n",
       "0  b3ae82c2-e60b-4551-a76d-6620f1b456aa          897  \n",
       "1  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8          706  \n",
       "2  21f3573f-10cf-44b3-aeaa-26cccd8448b5          507  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will set the dataframe index to be the artist name for easy reference in \n",
    "# the future\n",
    "artist_name = train[['artist_id', 'artist_name']].set_index('artist_id')\n",
    "train = train.drop(['artist_name'], axis=1)\n",
    "train.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the tags dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tags` dataframe has `artist_id` and one row per `tag`. There are some rows with empty tags, we will get rid of those as we have no use for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 tags missing. We must drop them.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>90s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3bd73256-3905-4f3a-97e2-8b341527f805</td>\n",
       "      <td>alternative punk rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              artist_id                    tag\n",
       "0  3bd73256-3905-4f3a-97e2-8b341527f805                    90s\n",
       "1  3bd73256-3905-4f3a-97e2-8b341527f805            alternative\n",
       "2  3bd73256-3905-4f3a-97e2-8b341527f805  alternative punk rock"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_cols = ['artist_id', 'tag']\n",
    "tags = pd.read_csv(\"../data/data/tags.csv\", header=None, names=tags_cols)\n",
    "# Null tags are of no use, and if there are some they must be removed.\n",
    "tags_null = tags['tag'].isnull().sum()\n",
    "print(\"There are {} tags missing. We must drop them.\".format(tags_null))\n",
    "tags = tags.dropna()\n",
    "tags.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include artists in both datasets only\n",
    "\n",
    "Now, we can only build artist profiles for artists with at least one tag assigned to them, otherwise there's nothing we can use to *describe* them.\n",
    "\n",
    "Similarly, artists with no playcounts are also useless to build user profiles. For convenience, we will remove them, *but could they be useful at some point*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We could try to use pandas.DataFrame.merge, why don't we?\n",
    "artists_intersect = np.intersect1d(tags['artist_id'].values, \n",
    "                                   train['artist_id'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove unnecessary artists from both dataframes, we will *select by label* the artists we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting by label only artists in tags that are also in train.\n",
    "tags = tags.set_index('artist_id').loc[artists_intersect].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selecting by label only artists in train that are also in tags.\n",
    "train = train.set_index('artist_id').loc[artists_intersect].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encode the `artist_id` on both dataframes\n",
    "\n",
    "While reasoning behind this step is not immediately clear, it's important that `artist_id` is encoded as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# We will use the sklearn.preprocessing.LabelEncoder for this but other \n",
    "# approaches are valid. This will fit an integer to each unique string.\n",
    "artist_encoder = LabelEncoder()\n",
    "tags['artist_id'] = artist_encoder.fit_transform(tags['artist_id'])\n",
    "\n",
    "# It is essential that we use the same encoder to transform the artists\n",
    "# in the train dataset, so that they have the same label on both sides.\n",
    "train['artist_id'] = artist_encoder.transform(train['artist_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort the tags dataframe by `artist_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, while not immediately clear why, this is a critical step: we need to assure that the `tags` dataframe is sorted according to the *encoded* `artist_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id          tag\n",
       "0          0          90s\n",
       "1          0     acoustic\n",
       "2          0  alternative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = tags.set_index('artist_id').sort_index().reset_index()\n",
    "tags.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the artist profiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should how many unique artists and tags we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2169 unique tags for 2420 unique artists.\n"
     ]
    }
   ],
   "source": [
    "unique_artists = len(tags['artist_id'].unique())\n",
    "unique_tags = len(tags['tag'].unique())\n",
    "print(\"There are {} unique tags for {} unique artists.\".format(unique_tags, \n",
    "                                                               unique_artists))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the top 3 most common tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock          2349\n",
      "pop           1863\n",
      "electronic    1539\n",
      "Name: tag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tags_count = tags['tag'].value_counts()\n",
    "print(tags_count[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a random sample of 5 of the most obscure tags, just for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latin alternative                                        1\n",
       "electric delta blues                                     1\n",
       "1 7 186240 183 23558 41608 89158 111733 150833 169883    1\n",
       "harp                                                     1\n",
       "dark folk                                                1\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_count_one = tags_count[tags_count == 1]\n",
    "np.random.seed(1)\n",
    "# We will randomize the order of the tags with count one so we can select 5 \n",
    "# obscure tags at random.\n",
    "randomize_order = np.random.permutation(len(tags_count_one))\n",
    "tags_count_one[randomize_order][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all tags in a single *document* per artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing is, instead of a single tag per row, we need a single entry per arist, to have *collection* of tags per artist, resembling a *document*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90s acoustic alternative alternative rock braz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00s acoustic alternative alternative rock beau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>acid jazz afrobeat alternative rock ambient bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id                                                tag\n",
       "0          0  90s acoustic alternative alternative rock braz...\n",
       "1          1  00s acoustic alternative alternative rock beau...\n",
       "2          2  acid jazz afrobeat alternative rock ambient bi..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are probably less hacky ways to do this but it's not too expensive,\n",
    "# it's interpretable and serves the purpose well.\n",
    "# We are concatenating all tags as word in a single sentence.\n",
    "tags = tags.groupby('artist_id')['tag'].apply(' '.join).reset_index()\n",
    "# Some words, previously associated with particular tags, will appear more\n",
    "# than once (e.g. 'alternative' in the second row).\n",
    "tags.head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When talking about musical genres, people tend to use 'alternative rock' and 'alternative-rock' interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# At this point, do things that don't scale. Try to spot possible strategies to\n",
    "# improve the quality of your documents.\n",
    "tags['tag'] = tags['tag'].str.replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structuring the tags data (aka vectorization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And no, we are not using word-to-vec.\n",
    "\n",
    "A vector exists in a space, in this particular case, a high-dimensional space corresponding to all the tags in our dataset. \n",
    "\n",
    "We take each word appearing in the documents as a dimension, or a feature. Each document is then represented as a *keyword vector*, typically with counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighting different words\n",
    "\n",
    "TF-IDF stands for Term Frequency - Inverse Document Frequency and is a *weighting* function.\n",
    "\n",
    "Why do we need it? Because not all terms are equally relevant to describe an artist. In short, we measure the term frequency, weighted by its rarity.\n",
    "\n",
    "$$ IDF _{term} = log\\left({\\frac{TotalDocuments}{DocumentsWithTerm}} \\right) $$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$ TFIDF _{term} = TF _{term} * IDF _{term} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "\n",
    "# Add language stemmer to TfidfVectorizer by overriding the built-in \n",
    "# build_analyzer()\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    # Stemming reduces words to their most basic form, to minimize the\n",
    "    # feature space.\n",
    "    def build_analyzer(self):\n",
    "        stemmer = EnglishStemmer()\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words representation with TF-IDF\n",
    "\n",
    "We will now build our dictionary of tags and project our artist documents in our vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the vocabulary ['90s', 'acoust', 'altern', 'rock', 'brazil', 'brazilian', 'pop', 'music', 'dancehal'].\n",
      "There are 774 unique tags.\n"
     ]
    }
   ],
   "source": [
    "# Bad of words representation, considering words with document frequency\n",
    "# of at least 3 documents, otherwise they are not useful.\n",
    "vectorizer = StemmedTfidfVectorizer(min_df=3, analyzer='word', \n",
    "                                    stop_words='english', lowercase=True)\n",
    "\n",
    "# Build internal dictionary.\n",
    "vectorizer.fit(tags['tag'])\n",
    "\n",
    "# We call the dictionary the collection of distinct words.\n",
    "vocabulary = list(vectorizer.vocabulary_)\n",
    "print(\"Sample of the vocabulary {}.\".format(vocabulary[:9]))\n",
    "print(\"There are {} unique tags.\".format(len(vocabulary)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a sparse matrix of keyword vectors\n",
    "\n",
    "We trained our dictionary, now we need to transform our `tags` dataframe into keyword vectors, with all the labels as features.\n",
    "\n",
    "As you can see, the result is a sparse matrix. But what is that, right?\n",
    "\n",
    "The reason why we sorted the artists, is because our vectorizer maintains the order of the rows, and we will perform some algebra on top of this very soon.\n",
    "\n",
    "(This is a hint!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2420, 774) <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# This will generate a sparse matrix with our artists in the rows, and\n",
    "# the tags as columns.\n",
    "artists_matrix = vectorizer.transform(tags['tag'])\n",
    "print(artists_matrix.shape, type(artists_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note about normalization\n",
    "\n",
    "Normalizing the artist keyword vectors is key, otherwise artists with more tags will have more weight on user profiles.\n",
    "\n",
    "By normalizing, we mean making all vectors length 1.\n",
    "\n",
    "We accomplish this with the following formula:\n",
    "\n",
    "$$ \\vec{u} = {\\frac{\\vec{v}}{\\parallel\\vec{v}\\parallel}} $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ \\parallel\\vec{v}\\parallel = \\sqrt{v_1^2 + v_2^2 + ... + v_n^2} $$\n",
    "\n",
    "So, we take the non-normalized vector and divide it (i.e. all its components) by its own magnitude, also called length, or *norm*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building user profiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating a sparse matrix with users, items and playcounts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse matrix is a big matrix where most of its elements are 0. \n",
    "\n",
    "The idea behind sparce matrices is to just store the information relative to the non-zero elements of the matrix. \n",
    "\n",
    "This makes working with these matrices way easier, and more performant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "# We also need to transform the user_id into an integer.\n",
    "# The row index in our sparse matrix.\n",
    "rows = user_encoder.fit_transform(train['user_id'])\n",
    "# The column index in our sparse matrix.\n",
    "cols = train['artist_id'].values\n",
    "data = train['play_counts'].values\n",
    "\n",
    "# [row_ind[k], col_ind[k]] = data[k]\n",
    "users_matrix = csr_matrix((data, (rows, cols)), shape=(rows.max() + 1, cols.max() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239929, 2420)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_profiles = users_matrix.dot(artists_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239929, 774)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions (and another note about normalization)\n",
    "\n",
    "An alternative to normalizing our vectors is to just compute the cosine between movie profile and the user taste.\n",
    "\n",
    "This is because the cosine *is a dot-product that is already normalized*:\n",
    "\n",
    "$$ cos(\\vec{u}, \\vec{v}) = \n",
    "\\frac{\\langle \\vec{u}, \\vec{v} \\rangle}{\\parallel\\vec{u}\\parallel\\parallel\\vec{v}\\parallel} $$\n",
    "\n",
    "In fact, the predictions will be *scalled by the user taste vector norm*, but that's ok because the order between the items will be kept unchanged.\n",
    "\n",
    "Let's build our prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stabbing westward'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def make_one_prediction(user_id):\n",
    "    encoded_user_id = user_encoder.transform(user_id)\n",
    "    user_preferences = user_profiles[encoded_user_id, :]\n",
    "    encoded_artist = cosine_similarity(user_preferences, artists_matrix).argmax()\n",
    "    artist_id = artist_encoder.inverse_transform(encoded_artist)\n",
    "    artist = artist_name.loc[artist_id].values[0][0]\n",
    "    return artist\n",
    "\n",
    "make_one_prediction(['00000c289a1829a808ac09c00daf10bc3c4e223b'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
